{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning on Perovskites Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "data =  pd.read_csv('new_stability_output_with_descriptors.csv', index_col=0) \n",
    "cdata = pd.read_csv('continuous_stability_output_with_descriptors.csv',index_col=0)\n",
    "ddata = pd.read_csv('disc_stability_output_with_descriptors.csv',index_col=0)\n",
    "X = data[data.columns[0:-1]]\n",
    "Xc = cdata[cdata.columns[0:-1]]\n",
    "Xd = ddata[ddata.columns[0:-1]]\n",
    "y = cdata[cdata.columns[-1]]\n",
    "## store yl as continuous target for regression work\n",
    "mdata = pd.read_csv('continuous_stability_output_with_descriptors.csv',index_col=0)\n",
    "yl = mdata[mdata.columns[-1]]\n",
    "# label the instance for classification work\n",
    "# Energy above 40 meV is considered to be unstable\n",
    "y[y<=40] = 1\n",
    "y[y>40] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "yhist = yl.plot.hist(bins=1000)\n",
    "plt.xlim(0,400)\n",
    "plt.xlabel('Energy above hull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "## scale the features\n",
    "## This part is a little cheating, need to be visited later. But currently, this won't affect much.\n",
    "Xc_scaled = preprocessing.scale(Xc)\n",
    "Xd_scaled = preprocessing.scale(Xd)\n",
    "## remove constant feature\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold()\n",
    "Xc_ns = sel.fit_transform(Xc_scaled)\n",
    "Xd_ns = sel.fit_transform(Xd_scaled)\n",
    "## do PCA learning, keep 0.99 variance\n",
    "## select K-best, keep top 10 score features\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import pylab as pl\n",
    "pca = PCA(n_components=0.99)\n",
    "selection = SelectKBest(k=3)\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "Xc_con = combined_features.fit_transform(Xc_ns, y)\n",
    "Xd_con = combined_features.fit_transform(Xd_ns, y)\n",
    "X_features = np.concatenate((Xc_con,Xd_con),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "crand = RandomForestClassifier(n_estimators=100)\n",
    "mycv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "scores = cross_val_score(crand, X_features, y, cv = mycv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "cmlp = MLPClassifier(activation='relu', solver='adam', alpha=1e-1, hidden_layer_sizes=(35,8), max_iter=700)\n",
    "mycv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "scores = cross_val_score(cmlp, X_features, y, cv = mycv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features, y, test_size=0.2, random_state=300, stratify = y)\n",
    "\n",
    "cmlp.fit(X_train,y_train)\n",
    "y_true, y_pred = y_train, cmlp.predict(X_train)\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "y_true, y_pred = y_test, cmlp.predict(X_test)\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features, y, test_size=0.2, random_state=0, stratify = y)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = {'n_estimators': [10,30,50, 70,100,150],\n",
    "                    'class_weight' : ['balanced', None]}\n",
    "\n",
    "scores = ['precision', 'accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(RandomForestClassifier(n_jobs=4), tuned_parameters, cv=mycv,\n",
    "                       scoring=score, n_jobs = 4)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ROC CUrve\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "clf = RandomForestClassifier(n_estimators=70,class_weight='balanced',n_jobs=4)\n",
    "y_score = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    ytrue = np.array(y_test==i,dtype=int).reshape(-1,1)\n",
    "    fpr[i], tpr[i], _ = roc_curve(ytrue, y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',\n",
    "         lw=lw, label='ROC curve stable 1' )\n",
    "plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "         lw=lw, label='ROC curve stable 0' )\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic RF')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## validation Curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.utils import shuffle\n",
    "X_shuffled, y_shuffled = shuffle(X_features, y, random_state=0)\n",
    "my_param_range=[20,30,50,70,90,120,150,200,300]\n",
    "train_scores, valid_scores = validation_curve(clf, X_shuffled, y_shuffled, \n",
    "                                              param_name=\"n_estimators\", \n",
    "                                              param_range=my_param_range, cv= mycv, scoring=\"precision\",\n",
    "                                              n_jobs = 4)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(valid_scores, axis=1)\n",
    "test_scores_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Validation Curve with RF\")\n",
    "plt.xlabel(\"number of estimators\")\n",
    "plt.ylabel(\"Precision Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "param_range=my_param_range\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "title = \"Learning Curves (Random Forests)\"\n",
    "plot_learning_curve(clf, title, X_shuffled, y_shuffled, ylim=(0.5, 1.01), cv=mycv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "## clf = SGDClassifier(loss='hinge', penalty='l1', alpha=1e-3, n_iter=5, random_state=34)\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=clf, step=1, cv=mycv,\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X_features, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "pl.xlabel(\"Number of features selected\")\n",
    "pl.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "pl.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl.xlabel(\"Number of features selected\")\n",
    "pl.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "pl.plot(range(1, 20 + 1), rfecv.grid_scores_[0:20])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "clf = MLPRegressor(activation='relu', solver='adam', alpha=1e-1, hidden_layer_sizes=(35,8), max_iter=700)\n",
    "clf.fit(X_train, y_train)\n",
    "y_plin = clf.predict(X_test)\n",
    "pl.plot (y_test, y_plin, \"bo\", label='lin model')\n",
    "pl.ylim((-40,700))\n",
    "pl.xlim((-5, 700))\n",
    "pl.xlabel(\"EaboveHull\")\n",
    "pl.ylabel(\"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_plin = clf.predict(X_train)\n",
    "pl.plot (y_train, y_plin, \"bo\", label='lin model')\n",
    "pl.ylim((-40,700))\n",
    "pl.xlim((-5, 700))\n",
    "pl.xlabel(\"EaboveHull\")\n",
    "pl.ylabel(\"Predicted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
